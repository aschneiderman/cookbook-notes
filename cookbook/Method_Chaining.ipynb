{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf82348d",
   "metadata": {},
   "source": [
    "# Method Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed653a10",
   "metadata": {},
   "source": [
    "Method chaining is a way of writing pandas code that is not only more readable but also eats up less memory and runs faster (I think).\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "(autos\n",
    "[cols]\n",
    ".astype( {'highway': 'int8', 'number_gears': 'int8'})\n",
    ".select_dtypes(int,'int8')\n",
    ".describe\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9504eba",
   "metadata": {},
   "source": [
    "Junk drawer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376986f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    ".assign\n",
    "drive=autos.drive.fillna('Other').astype('Category'),\n",
    "automatic=auto.trany.str.contains('Auto')\n",
    "\n",
    ".str.extract(r'(\\d)+').fillna('20').astype('int8')\n",
    ".drop(columns=['bla'])\n",
    "\n",
    "\n",
    "# if:\n",
    ".assign(country=np.select(cond,true,false)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb6b08",
   "metadata": {},
   "source": [
    "to debug it: can easily comment out lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d3b34",
   "metadata": {},
   "source": [
    "## Code Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72675baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can also use query:\n",
    "\n",
    "df.assign(sp_int = df.Speed.str.replace(' ms', '').astype(int)).query('sp_int < 1000')\n",
    "\n",
    "\n",
    "Can turn this:\n",
    "new_df = (\n",
    "  df\n",
    "  .loc[ df.Speed.apply(lambda x: int(x.replace(' ms', '')) < 1000) ]\n",
    "  .assign(sp_int = df. Speed.apply(lambda x: int(x.replace(' ms', ''))))\n",
    "  ...\n",
    ")\n",
    "\n",
    "Into this:\n",
    "\n",
    "df_mc = pd.read_csv('data/src/sample_pandas_normal.csv', index_col=0).assign(point_ratio=df['point'] / 100).drop(columns='state').sort_values('age').head(3)\n",
    "df_mc_break = pd.read_csv(\n",
    "    'data/src/sample_pandas_normal.csv',\n",
    "    index_col=0\n",
    ").assign(\n",
    "    point_ratio=df['point'] / 100\n",
    ").drop(\n",
    "    columns='state'\n",
    ").sort_values(\n",
    "    'age'\n",
    ").head(\n",
    "    3\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Clean up the `world_rank` \n",
    "def clean_world_rank(input_df):\n",
    "    df = input_df.copy()\n",
    "    df.world_rank = df.world_rank.str.split('-').str[0].str.split('='\n",
    ").str[0]\n",
    "    return df\n",
    "    \n",
    "# Assign the common years of `shanghai_df` and `times_df` to \n",
    "`common_years`    \n",
    "common_years = set(shanghai_df.year) & set(times_df.year) \n",
    "# Print `common_years`\n",
    "print(common_years)\n",
    "# Filter years\n",
    "def filter_year(input_df, years):\n",
    "    df = input_df.copy()\n",
    "    return df.query('year in {}'.format(list(years)))\n",
    "# Clean `times_df` and `shanghai_df`\n",
    "cleaned_times_df = (times_df.loc[:, common_columns]\n",
    "                            .pipe(filter_year, common_years)\n",
    "                            .pipe(clean_world_rank)\n",
    "                            .assign(name='times'))\n",
    "cleaned_shanghai_df = (shanghai_df.loc[:, common_columns]\n",
    "                                  .pipe(filter_year, common_years)\n",
    "                                  .pipe(clean_world_rank)\n",
    "                                  .assign(name='shanghai'))\n",
    "\n",
    "\n",
    "\n",
    "# Compose `ranking_df` with `cleaned_times_df` and \n",
    "`cleaned_shanghai_df`\n",
    "ranking_df = pd.concat([cleaned_times_df, cleaned_shanghai_df])\n",
    "# Calculate the percentage of missing data\n",
    "missing_data = 100 * pd.isnull(ranking_df.total_score).sum() / len\n",
    "(ranking_df)\n",
    "# Drop the `total_score` column of `ranking_df`\n",
    "ranking_df = ranking_df.drop('total_score', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "(pd.read_csv('data.csv')\n",
    "   .fillna(...)\n",
    "   .query('some_condition')\n",
    "   .assign(new_column = df.cut(...))\n",
    "   .pivot_table(...)\n",
    "   .rename(...)\n",
    ")\n",
    "Method Chaining has always been available in Pandas, but support for chaining has increased through the addition of new “chain-able” methods. For example, query(), assign(), pivot_table(), and in particular pipe() for allowing user-defined methods in method chaining.\n",
    "\n",
    "According to Titanic Data Dictionary, passengers departed from Southampton should have Embarked with value S . Let’s query that using the Pandas query() function.\n",
    "res = (\n",
    "  pd.read_csv('data/train.csv')\n",
    "    .pipe(replace_age_na, pclass_age_map)\n",
    "    .query('Embarked == \"S\"')\n",
    ")\n",
    "res.head()\n",
    "\n",
    "3. Convert ages to groups of age ranges: ≤12, Teen (≤ 18), Adult (≤ 60) and Older (>60)\n",
    "We did this with a custom function in the Pandas pipe function article. Alternatively, we can use Pandas built-in function assign() to add new columns to a DataFrame. Let’s go ahead withassign().\n",
    "bins=[0, 13, 19, 61, sys.maxsize]\n",
    "labels=['<12', 'Teen', 'Adult', 'Older']\n",
    "res = (\n",
    "  pd.read_csv('data/train.csv')\n",
    "    .pipe(replace_age_na, pclass_age_map)\n",
    "    .query('Embarked == \"S\"')\n",
    "    .assign(ageGroup = lambda df: pd.cut(df['Age'], bins=bins, labels=labels))\n",
    ")\n",
    "\n",
    "\n",
    "Create a pivot table to display the survival rate for different age groups and Pclass\n",
    "A pivot table allows us to insights into our data. Let’s figure out the survival rate with it.\n",
    "bins=[0, 13, 19, 61, sys.maxsize]\n",
    "labels=['<12', 'Teen', 'Adult', 'Older']\n",
    "(\n",
    "  pd.read_csv('data/train.csv')\n",
    "    .pipe(replace_age_na, pclass_age_map)\n",
    "    .query('Embarked == \"S\"')\n",
    "    .assign(ageGroup = lambda df: pd.cut(df['Age'], bins=bins, labels=labels))\n",
    "    .pivot_table(\n",
    "        values='Survived', \n",
    "        columns='Pclass', \n",
    "        index='ageGroup', \n",
    "        aggfunc='mean')\n",
    ")\n",
    "\n",
    "(ramen['Stars']\n",
    "     .replace('Unrated', None)\n",
    "     .dropna()\n",
    "     .astype('float64')\n",
    "     .head())\n",
    "     \n",
    "     \n",
    "\n",
    "do\n",
    "\n",
    "(pd.read_csv('data.csv')\n",
    "   .fillna(...)\n",
    "   .query('some_condition')\n",
    "   .assign(new_column = df.cut(...))\n",
    "   .pivot_table(...)\n",
    "   .rename(...)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We can see the wealthier passengers in the higher classes tend to be older, which makes sense. We’ll use these average age values to impute based on Pclass for Age.\n",
    "pclass_age_map = {\n",
    "  1: 37,\n",
    "  2: 29,\n",
    "  3: 24,\n",
    "}\n",
    "def replace_age_na(x_df, fill_map):\n",
    "    cond=x_df['Age'].isna()\n",
    "    res=x_df.loc[cond,'Pclass'].map(fill_map)\n",
    "    x_df.loc[cond,'Age']=res\n",
    "    return x_df\n",
    "x_df['Age'].isna() selects the Age column and detects the missing values. Then, x_df.loc[cond, 'Pclass'] is used to access Pclass values conditionally and call Pandas map() for substituting each value with another value. Finally, x_df.loc[cond, 'Age']=res conditionally replace all missing Age values with res.\n",
    "Running the following code\n",
    "res = (\n",
    "  pd.read_csv('data/train.csv')\n",
    "    .pipe(replace_age_na, pclass_age_map)\n",
    ")\n",
    "res.head()\n",
    "All missing ages should be replaced based on Pclass for Age\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let’s start by checking out missing values. We can use seaborn to create a simple heatmap to see where are missing values\n",
    "sns.heatmap(df.isnull(), \n",
    "            yticklabels=False, \n",
    "            cbar=False, \n",
    "            cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9edc9",
   "metadata": {},
   "source": [
    "### To Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ae944",
   "metadata": {},
   "source": [
    "\n",
    "using .pipe?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb0994",
   "metadata": {},
   "source": [
    "proper pandas -- eg chaining:\n",
    "https://youtu.be/UURvPeczxJI\n",
    "\n",
    "Using Pandas method chaining to improve code readability\n",
    "https://github.com/BindiChen/machine-learning/blob/master/data-analysis/007-method-chaining/method-chaining.ipynb\n",
    "\n",
    "Assign and chaining\n",
    "https://www.metasnake.com/blog/pydata-assign.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036d78e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
